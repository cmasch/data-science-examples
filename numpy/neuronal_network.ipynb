{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How neural networks learn\n",
    "Understanding the basics of neural nets and its mathmatics is an essential part working with them. I expect knowledge about vectors and matrices.<br>\n",
    "In the following I will explain the most important parts to create a small and simple neural net using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "An activation function is used in neural networks to define the outputs of neurons.<br>\n",
    "The most popular activation functions are sigmoid, tanh and ReLU.\n",
    "\n",
    "<br>\n",
    "**Sigmoid:**<br>\n",
    "$\\sigma(z)=\\frac{1}{(1+e^{-z})}$\n",
    "\n",
    "Sigmoid neurons are similar to perceptrons, but modified that small changes in their weights and bias cause only a small change in their output. Sigmoid neurons give us flexibility of continous values between 0 and 1.<br>\n",
    "\n",
    "<br>\n",
    "**Hyperbolic tangent (Tanh):**<br>\n",
    "$tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$\n",
    "\n",
    "Tanh is quit similiar to Sigmoid. The output values ranges from -1 to 1. In the case of sigmoid the output values are between 0 and 1. You can modify the sigmoid function to get the same output of tanh:<br>$tanh(z) = 2 * \\sigma(2 * z) - 1$<br>\n",
    "\n",
    "<br>\n",
    "**Rectified linear unit (ReLU):**<br>\n",
    "$relu(z) = max(0,z)$\n",
    "\n",
    "ReLU is on of the most popular activation function for deep neural networks.<br>\n",
    "One drawback of ReLU is when the weighted input to a rectified linear unit is negative. This causes in the gradient vanishes and so the neuron stops learning entirely. As an example:<br>$relu(-100.99) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find some visuzalitions of this three functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8HOW97/HP9lVZSStpJVmSe3nccMOFFlogAQI4oUMg2PSTcBLCyeUSOCk355XX4Z7knoSTQgDbYIrjEEILOCH0GoMNGOP2uGFbkq3etautc//YtSwby7a0K+3I+3u/XstOeWbmKyH/NJp95hmLYRgIIYQ4/lnTHUAIIcTQkIIvhBAZQgq+EEJkCCn4QgiRIaTgCyFEhpCCL4QQGcKe7A6UUiOBx4BSwAAe0lrff0gbC3A/cAHgBxZprT9O9thCCCGOXSrO8CPAv2mtpwInAd9RSk09pM35wMTE6xbggRQcVwghRD8kXfC11vv2n61rrTuAzUDFIc0WAo9prQ2t9WqgQCk1ItljCyGEOHZJX9LpTSk1BpgNfHDIqgqgqtd8dWLZviPtLxKJGna7LZURhRBp0r5pM5/d+2NcxcXM+vUvsefkpDvS8crS14qUFXylVC7wF+AOrXV7KvbZ0uIf8LY+n4eGho5UxEgps+YC82Yzay4wbzaz5Yr6/ez+5a/AMJj0/e/S4o+B3zz5wHzfs976k83n8/S5LiW9dJRSDuLF/kmt9TOHaVIDjOw1X5lYJoTIAPUrHifS1ETh1y4ib+qUdMfJWKnopWMBlgKbtdb/3UezF4DblVIrgQVAm9b6iJdzhBDHh/YPVtOx+p+4x46j6MKL0x0no6Xiks6pwHXAZ0qpdYll9wCjALTWfwBWEe+SuZ14t8zFKTiuEMLkwk1N1D+xHIvLRdlNt2Kxp/RjQ9FPSX/3tdbvcoQPCRJtDOA7yR5LCDF8GLEYtUsfIhYIULroBpylpemOlPHkTlshxKBo+fsqAls1uSfOJe/UL6U7jkAKvhBiEHTv+pzG55/FVlBA6XWLsFiOeBFADBEp+EKIlIoFg+x7+EGIRim74WZsubnpjiQSpOALIVKq4U9/JFxXi/cr55EzdVq644hepOALIVKm85OPaXv7TVwjR1L0jUvTHWfAli9fyrXXXsH111/FokXXsHHjBu677z/4/POdg3rcH/zgu3R0fPEGq9/85jesWPF40vuXPlJCiJSItLZSu3wZFoeDsptuw+pwpDvSgGzYsJ7333+XZcuewOl00traSiQS5u67fzTox/7lL/9nUPcvBV8IkTQjFqP2kSXEOjvxXf1NXBWHjp84fDQ1NZKfX4DT6QSgoKAAgNtvv4Xbb7+DyZOn8uKLz/HEE4/h8eQyYcIkHA4Hd975v/n5z3+Ky+Vi61ZNS0sLP/zhj/j7319i48bPmDp1Ovfe+1MAXnnl7zz++CMYhsHJJ5/Gt7/9XQAuu+wilix5nIKCApYvX8rf/vYSXq+XUaMqGT16QtJfmxR8IUTSWl9/Df/GDWRPn0HB2eekZJ9Pvb6dNVvqU7Kv/eZNLuGKs49cOOfNO4lHHlnCVVddwty58/nyl89l9uwTe9Y3Njbw6KNLWbbsCbKzc/jud29jwoSJPes7Otp58MFHePfdt7j77n/jgQeWMnbsOG666Vts26bxegt54IHfsHTpE3g8Hu6883befvtNTj/9zJ59bNmymdde+wePPrqCaDTCzTd/KyUFX67hCyGSEqyuovHpP2HL9VC2+IZh3wUzOzubpUsf56677sHr9fKTn9zDqlV/7Vm/adNGZs2aQ15ePna7nbPOOvgX3Kmnno7FYmHcuAkUFhYyfvwErFYrY8eOY9++fWzevJHZs0/E6/Vit9v5ylfO49NPD34e1Pr1n3D66WfhdrvJycnl7LPPTsnXJmf4QogBi4VD7Hv4QYxIhNJFN2DPL0jZvq84e8JRz8YHi81mY86cucyZM5dx48bzt7+9dMzbOhKfXVit1p7p/fPRaAR7GoeXkDN8IcSANf7laUI11eSfcRa5s2anO05K7Nmzi6qqPT3z27ZtpaysrGd+ypSprFv3Me3t7UQiEd566/V+7X/KlOmsW/cxra2tRKNRXnnlH8yaNeegNjNnzuGdd94kGOzG7+/ijTfeSO6LSpAzfCHEgHRt3EDrq//AUVaG74qr0h0nZfz+AL/+9S/o7OzAZrNRUTGSu+66l3//97sA8PlKuO66xdxyy/V4PHmMHj2GnJxjv7msuLiY2267ne9+99aeD22/9KUzD2qj1GTOPvtcrr/+GrxeLyeccEJKvjaLYRgp2dFgaGjoGHA4sz7MwKy5wLzZzJoLzJttsHNFOzrY9dN/J9rZyah7foR79BjTZBuo/uTy+/1kZ2cTiUS4557/xde+djFnnHGWKbL5fJ7Bf+KVECIzGIZB7fJlRNvaKL70in4V++PFsmUPsXbth4RCQebPP+mgHjZmJgVfCNEvbe+8Rde6T8hSk/F+9bx0x0mL22+/I90RBkQ+tBVCHLNQbS0NK1dgzc6m7MabsVilhAwn8n9LCHFMjEiEfUsexAiFKL1uEY7ConRHEv0kBV8IcUyaXniO4K7PyTvlVDzz5qc7jhiAlFzDV0otAy4E6rXW0w+z/kzgeeDzxKJntNY/S8WxhRCDz79V0/y3l3AU+/BdfW2644gBStWHto8CvwUeO0Kbd7TWF6boeEKIIRL1d1G75CEAym66BVtWVpoTDZ62tla+971vA9Dc3ITVaqWgwAvAww8vP+jO2aP52c9+xJlnftlUPXhSUvC11m8rpcakYl9CCHOpf/JxIs1NFF60kKxeg4Qdj/LzC3j00RUALF36IFlZ2VxzzXVpTpU6Q9kt82Sl1KfAXuAHWuuNQ3hsIcQAtK9+n44PVuMeN56iCy9Od5y0uuuu79PY2EAoFOLKK6/hoou+TiQS4cILz2HhwktZvfp93G439933//B6CwH4+OO1rFjxGE1NTdx++x2DenPWsRiqgv8xMFpr3amUugB4DjjqqYLXm43dbhvwQX0+z4C3HUxmzQXmzWbWXGDebMnm6q6rZ8eKJ7C63Uy9606yylI3MNqxZHt83V9YXfXxUdv1x0kj53DdrL6fxNU7V06Oi+xsV8+yX/3qlxQUFBAIBLj00ku59NKL8Xo9dHZ2csYZp/LjH9/Df/7nf/Lmmy9zyy234HLZCQQ6ePrpp9Bac8cdd3DZZQP/pZmKn7MhKfha6/Ze06uUUr9XShVrrRuPtF1Li3/Axzwebt8eambNZtZcYN5syeYyYjGqf/Eron4/pYtvpNOeQ2eKvs5jzeYPhIjGUjv0iz8Q6vPYh+bq6goSi9l6lj388EO8++7bAOzbV8v69VuYMGESLpeLqVPn0NDQwahR4/n0009oaOggGIxw6qlforGxk6KiCmpr6wb8/6SfQyv0uW5ICr5Sqgyo01obSqn5xLuDNg3FsYUQ/de86kUC27aSe+Jc8k45LS0ZLplwIZdMMEc/jzVrPuDTTz/hoYceweVy8y//ciPBYAjgMEMgR3vmHQ5nr72kf9yyVHXL/CNwJlCslKoGfgI4ALTWfwAuA/5FKRUBAsBVWuv0f/VCiC8I7NxJ0wvPYfd6Kb1u0bB/oEkqdHV14vHk4XK52blzB1u2bEp3pAFJVS+dq4+y/rfEu20KIUws1t1N7ZIHwTAou+FmbLnHPuzv8ezkk0/jhRee5dprL2fkyNFMnfqF242GBRkeeYiZNReYN5tZc4F5sw00V+2jy2h/9228Xz0P3+WDM8b98fY9GwqpGh5ZhlYQQgDQ8fFHtL/7Nq5Royn6et89WcTwJQVfCEGktYW65cuwOByU3XQr1n7cUSqGDyn4QmQ4IxajdukSYl1d+K64Cld5ebojiUEiBV+IDNf66iv4N28kZ8ZM8s88O91xxCCSgi9EBgtW7aHxmT9j8+RRuuhG6YJ5nJOCL0SGioVC7Hv4QYxIhNLFN2LPy0t3JDHIpOALkaEan36K0N4a8s/6MrkzZqY7jmmcfvp8Fi26huuuu4K77vo+HR1H7w557rlf+sKyn//8p7zxxqtHbTeUpOALkYG6PltP6+uv4hxRju/yK9Mdx1RcLhePPrqCxx9/iry8PJ555ql0R0qZoRweWQhhApH2dmofWQI2G2U334rV6Tz6Rhlq+vQT2L59e8/8ihWP8frrrxIOhzj99LO48cZb05iu/6TgC5FBDMOgbvkyou3tFF9+Je5Ro9MdqU8Nf15Jx9o1Kd2nZ+68Y76DOBqNsnbtGi68cCEAH364mqqqKh5+eDmGYXD33Xeybt3HzJo1J6UZB5MUfCEySNtbb9D16TqyJk/Be+5X0x3HlILBIIsWXUNjYz2jR49l3rwFQLzgr1mzmsWLvwlAIOCnunpPnwX/8D2e0tsLSgq+EBkitG8vDU+txJqdQ9kNN2OxmvsjPN/lVw3aeD5Hsv8afnd3N3feeTvPPPNnLr/8KgzD4NprF/H1Yxx2Ii8v/6APfNvb2ygoSN1DZAbC3P/HhRApYUQi8S6YoRCl31qEo7Aw3ZFMz+12c8cdP2DlyieIRCIsWHAyL730An5//MFMDQ31tLQ097n97Nkn8tprrxAOhwFYteqvzJ594pBk74uc4QuRARqfe4bgnt3knfolPHPnpTvOsDFp0mTGj5/Iq6++zHnnfY1duz7nttsWA5CVlc2Pf/wfeL2FdHd3841vXNCz3ZVXXsNVV12L1pu58cZrsVptVFRU8IMf3JOuLwWQ4ZGHnFlzgXmzmTUXmDdb71z+LZup/n//haPYx+if/B+s7izTZDMTs+YCGR5ZCHEMol1d1C59GCwWym66Je3FXqSXFHwhjlOGYVD3+HIiLc0UXbSQrPET0h1JpJkUfCGOUx3/fJ/OtR/iHj+BwgvM8TBwkV6peoj5MuBCoF5r/YWHPSqlLMD9wAWAH1iktf44FccWQnxRd10d9Ssex+p2M+KmW7HYbOmOJEwgVb10HiX+kPLH+lh/PjAx8VoAPJB4F0KkmBGNsvVX9xPr7qbsxptx+HzpjnTcMQwDAwPDMIgl3vfPw/5pEtMH2u9fsn/dgRYH9guQ48jBaUv9U8dSUvC11m8rpcYcoclC4DGttQGsVkoVKKVGaK33peL4QogDmle9SMcWjWfefDwnnZLuOAMWjUUJRLsJRoJ0R4MEo0G6I0FCsTChaIhgNEQ4GiIcixCOhQnFwkRikcQrGn83okQT81Ej2vMeM2K93mPEjBhYDCLR+LJ4IY8vjxkGhhE7qLAPNq+rgP845Ycpfz7BUPXDrwCqes1XJ5YdseB7vdnY7QP/U9Tn8wx428Fk1lxg3mxmzQXmytaht9L01+dxFhcz9Y7vYM/NTXekHt3hbpoCrWyoq6G1u4O27nbagh20d3fQEeqiM9RFR7CLrrAffzhe6FPNZrFitdqwW2zYrImXxYrNasVqseGyObFarFgtlsR7/BUvvBYwwDAsxGKJs3bDghGDWMwgZtCzPBaLT8d6puNn9dGYEZ/uvc6IL4vFDuQMWIrx+TwHFfxU/JyZ+sarlhb/gLc1a59as+YC82Yzay4wV7ZYd4Ddv/gVGAaTvv9dWgIGBIYuWzQWpSHQRL2/gcZAE43dzTQGmmnubqE12EYg0n3E7S1YyLZnkWV3U5JVTFZi2m1z4bK5cNvj7y6bE6fVgdPmxGlz4LA6cFjtOBLTdosNu9WB3WrHYbVhtdiwW20YMQtd3RG6AmE6A+Ge6a7uCP5gmBgWmtsC+Lsj+IMRuoIRuoMRAsEogVCEVNyyZLdZcNitOOw2XHZrfNpmxZ54d9it2G1Wxpbn0djY2bNdP/vh9338pL+CY1MDjOw1X5lYJoRIkfo/riDcUI/3/K+RP33aoP0iMgyDtlA71R17qeqoobpzH7VddTQEmoga0S+0z7K78boKGJuXT4ErnxHeYuwRJx6nB48zF48jhxxHDtmOLKyWY+84aBgG/mCEts4Qbe0hmjqDtHeFaPf7E+8hOvxhOgMhOgNhAsEvZuuLxQJZTjtZLjuFeW6yXDbcTjtupy3xOjDtctpwOeIvp8OGy2HtWeawW3E6bDjtVpx2G1ZrZgye9gJwu1JqJfEPa9vk+r0QqdOxdg3t772Da9Roihd+I6X7jsQiVHXsZWfbLna07WJn2y46Qp0HtXHb3IzyVFCaU0Jptg9fVjHFWYUUuQvJdhx8s9exnK0ahkG7P0xze3fiFaS5o5uWjiCtHUFaOoO0doYIR2JH3I/NasGT7aA4P4vcLEfPKyfLTo7bkXjZyXbbqSwvIOgPkuWKF/Pj8fm+qeqW+UfgTKBYKVUN/ARwAGit/wCsIt4lczvxbpmLU3FcIQSEW1qoe+xRLE4nI265DYs9+X/W9f5GNjVrNjdptrbsIBQL96wrcOUzs3gaIz0VVHrKqcwtp8CV3+8CGQhGqG8J0NAaoKEtQENrNw2tAZraumlq7+6zmFsskJfjpLw4h4IcJ/m5LvJznBTkOvFkO8nLcZKfE5/Och174TbT5bnBkqpeOlcfZb0BfCcVxxJCHGDEYtQufYiYv4uS667HWTZiYPsxDKo79/Jx/Xo+qV9PQ6CpZ11ZdgmTvOMZlz+G8QVjKHR7j3m/kWiMhtYAtU1+9jX7qW3y09wZpLq+k/au0GG3yc1yUF6UQ1G+m6I8N0V5Lgrz3Hg98fe8HAc2kw/tbFam/tBWCHFkLa+8TGDLZnJmzSb/9DP7vX1joJl/7lvD2rp1NCaKvNPmZJZvOlMLFVOKJh1TgY/FDOpbA1TXd1Ld0MneJj97G7uoa/YTjR38aafVAkX5bqaPLaTEm0WJNxtfvhtfQRZF+W6yXFKWBot8Z4UYprr37Kbxmaex5eVRev3iY750EYlFWN+4ifdqPkC3bMfAwGlzcmLJTOaUzGBq0eQj3vQTDEWpqu9kT30He+o62FPXyd7GLkKHXILJctkYU+ZhRFEOI4qyKSvMpqwomykTSmht6UrqaxcDIwVfiGEoFgxS+/CDEI1SdsNN2D15R92mOxLkvb0f8HrVO7QG2wAYlz+G08oXMLvkBJy2Lz7MPByJsaeug121HXy+r51dtR3sa+w66NYju81CeVEOlSW5VPpyqfTlUF6cg9fjOuwvIYddLsekixR8IYahhqefIrRvLwVnn0PO9BlHbNsV9vNG1bu8Vf0e/kgAp83JmZWnclrFSYzIKT2obVNbN9tqWtlZ086Ove1U1XcQiR4o7y6njYmV+Ywq8zC61MOoUg8jirKx26SIDwdS8IUYZjrXr6PtjddwlldQfNkVfbYLR8O8Wf0eL+9+nUCkmxxHNheO/QqnV55CjiObmGFQVd/J1qpWtlW3sq26jZaOA3e32qwWRpXmMm5EPmPLPYwpy6OsMDvtfcnFwEnBF2IYibS1UffIMix2OyNuvhWr84uXYWJGjLd3fcCT656jJdhKjj2bSyZcyCnlC2hoCvHeJ41s2RMv8l3dkZ7t8rIdzJnkY0JFPhMq8hldlosjiaFNhPlIwRdimDAMg7pHlxLtaMd3xVW4Ro76Qpvarjqe3PIXdrbtwm61c0rJqfiC09Ef+Xn+2Q/pDBzoT1+c72bWhGImjSxg0sgCSrxZx+XNRuIAKfhCDBNtb75O12fryZ4yjYJzvnLQukgswj92v8Hfd71O1IhSzDgC2yfy2moLsBsAr8fFqdPLmDzay+RRXory3Wn4KkQ6ScEXYhgI7t1Lw1MrsebkUHbjTVgSNx4ZhsEn1Tt5avuf6TCaMUIuQrtmUNVaSpbLxuyJXqaNLWTamEI5gxdS8IUwu1g4TO3Df8AIhym76VaM3Hw27Gxi3fZGPmpaQ9C3AYs1RqRuJGWhE5k5tYwvzamkMNsud6SKg0jBF8Lkmp57hmDVHrqnzeXxKjcb3nqH7mg3zrEbsJXWYY+5OC3vfM5bMJe8nPiHuJkwLozoPyn4QphUS0eQTW+spvjlv9Hq8LAsMJHwlnoKS4K4R68haOlkQv5YFk+/hgJXfrrjimFACr4QJtLYFuAj3cBaXU/NngZu2PNXDCysmfpVLjxRkVvaxAvVzxKKhjh/zDlcMPacfo0hLzKbFHwh0qyxNcAaXc/aLfV8vi9+GcaCwbWdH5EX9ZN1/sV855Kv8VrV2/xl+yrsVjs3Tb+O2SUnpDm5GG6k4AuRBo1tAdZuaWDNlrqeIm+1WJg2xsuJk0uY3LyN9hXbyZo4iRELL2LFlr/w/r4PyXfmcduMRYzKq0zzVyCGIyn4QgyR1s4ga7bU8+HmOnbUtAOJIj+2kHmTS5gzyUduloNQfT27H16JNSuL4sU38Mjmlaxr+IyRngpum7FIrteLAZOCL8Qg6gyE+UjX88GmOvSeVgziT2yaMtrLvCklnDjJhyf7wPAIRjRK7ZIHMYLdFN1wI8v2vcSmJs3EgnHcNmMRbrvcLCUGTgq+ECnWHYqwblsjqzfVsfHz5p4HgEyozGfBlFLmKh/5ua7Dbtv04gt079xB9rx5PObeyLamnUwtUtw8/VtHHKNeiGORqmfangfcD9iAJVrr+w5Zvwj4BVCTWPRbrfWSVBxbCDOIRGNs2NnM6k21rNveSCgcfxjIqNJcFkwtZf7k0qMOZRDYvo3mF1/AVljI09MjbGvdzSzfCSyedjV2q5ybieQl/VOklLIBvwPOBaqBNUqpF7TWmw5p+iet9e3JHk8Is4gZBht2NPLy+5+zZkt9z8iTJd4sTppayoKppYwoyjmmfUUDAWqXPATAe6ePYFuwhnmls7luyhXYrDJipUiNVJw2zAe2a613AiilVgILgUMLvhDDnpEYQ/6DTXV8sLmO5vb4+PH5OU7OnTuSk6aVMqbM0+8xaxpWPEG4sYHP547ig+wGZvqmS7EXKZeKgl8BVPWarwYWHKbdpUqp04GtwPe11lWHaXMQrzcbexLjcft8ngFvO5jMmgvMmy3duWqbunjrk2re+riGqrp4N8pst51z5o3izDmVTJ9QjG2ADwZpeOc92v/5Hl1l+bw4IcDMsqncddotOJK8Zp/u79mRmDWbWXNBarIN1YXBvwJ/1FoHlVK3AsuBs4+2UUuLf8AHNOtYImbNBebNlq5cbZ1BPtwS72Gzc2+8G6XdZuVE5eOkqaXMGF9E+YgCGho6aG7qHNAxws1N7P79H4jabTw918ZY71iuV9+ktbkb6B5wdrP+vwTzZjNrLuhftiP9YkhFwa8BRvaar+TAh7MAaK2bes0uAf4rBccVIuX83WE+0g2s3lTHlj0tGEa8G+W0MV4WTC1jziQf2e7UnCcZsRi1Sx4i5vfzxnwPueWj+JeZi3Ed5mHiQqRCKn5y1wATlVJjiRf6q4BrejdQSo3QWu9LzF4MbE7BcYVIie5QhHXbG/lwUz0bPm/qeWj3+Io85k8pZf6UUvJzUl+EW17+G4Gtmh2VTmqmlvK/Zi4my56V8uMIsV/SBV9rHVFK3Q68TLxb5jKt9Ual1M+AtVrrF4DvKqUuBiJAM7Ao2eMKkYxgOMpnO5r4cEs967c3EorEu1FW+nJZMLWEBVNKKS4YvOLbvXsXjc89Q5fbyjsnF/HtmTfIHbRi0KXkb1Ot9Spg1SHLftxr+ofAD1NxLCEGan+RX6vrD+orX1aYzfwpJcyfUkp58bF1o0xGLBik+sHfQTTKq6d7+ebcRVR6ygf9uELI3RziuNYdirB+RxNrt9SzfmdTT5Ev8WYxb3IJ8yaXMLIkd0gf/Vf7pyeJ1TfwicripDOvZFqRGrJji8wmBV8cdzr8IdZtb+STrY1s+LyZSDRe5Eu9WcxNU5HvybbuEzrffpvGAhvWr53LlypOGvIMInNJwRfHhYbWAJ9sa2Tdtga2VrURM+IfvFYU5zBnko95k0uo8OWk9SHekbZWqpf9AcMKm746lcWTF6Yti8hMUvDFsBSLGXy+r51PdzSyblsj1Q1dPevGledx4iQfcyb5KC3MTmPKAwzDYPuD/4PNH+TD+cVcccYtchetGHJS8MWw0RkIs2lXM+t3NPHZziY6/GEgfjPUjPFFzJpYzMzxxXg9hx+JMp2qX34B69ad7B7h4rQr/pU8p3nv6BTHLyn4wrRiMYPPa9t5bd1eVn+2l51720lcqSE/18npM0cwY3wxU8d4cTvN+6PcVbWLzmefI+iy4Ln2asYUjE53JJGhzPuvRGQcwzCobw2weVcLG3c1s2V3S88IlBYLjK/I54RxRZwwrpBRpR6sabwef6xi4TDbfv/fZEcNai6cy9fUmemOJDKYFHyRVo1tAfSeVrbsbmHznpae0ScBivLc8XFrZlQwsiiLHPfwewDIxicfILuhnR2TCzn3glvTHUdkOCn4YsjEDIPaJj/ba9rQe1rZWtVCU68Cn+O2c6LyMWW0l2ljCinxZmGxWEw9qNWR1Hz8Hq53P6Y1z87sG+6UJ1aJtJOCLwZNIBhhV20HO/e2sb26je01bT2XaCBe4GdPLEaNLGDyaC+VJbnD4jLNsQi0tdD46CM4LWC/9nLKCivTHUkIKfgiNSLRGNUNneza18Gu2nZ27u2gprGz50NWgOJ8NyeML2JiRT4TRxZQXpxz3BT43gzDYP2D/4XXH6HmS1M4a85X0x1JCEAKvhiAQDBCTUMXu+s62FPXwZ66TmoaO3tGmQRw2q1MrCxgXHke48vzGFeeb8rukoNh499X4t26j4ayHE655o50xxGihxR80adwJEptc4C9jV3UNHZRXd9JdUMnjW0HP5jDbrNS6ctl7Ig8xpR5GDMij/LibGxWa5qSp0/Dnm1Ynv8HQYeFMbf+Ky5HZvySE8ODFPwMZxgG7V0h6loCfLyjme27m6lt9rOv2U99i/+gSzIAedkOpo7xUunLZVRpLqNKPJQVZWO3ZV5xP1Q0HGLnH36NN2LQetk5VIycnO5IQhxECn4GCEeiNLUHaWwL0NDaTUNrIP5qCVDXGiAYin5hmxy3nQkV+VQU5zCiOIfy4hwqfbmD8iCQ48WaJ/6Hwvou6iaXctpXv5nuOEJ8gRT8YS4cidHWGaS1M0RLZ5Dm9m6a24O0dHTT1B6kqb2b9q7QYbd1OqyUFGRT6s2ixJvFxNGF5DitlBVm48mWwt4fOz55m4JZkSjoAAAT60lEQVT3N9CRa2fWLXeldZA2IfoiBd+EQuEonYEwHf4wHf4QbV0hOvxh2v0h2jpDtHcFaesK0doZojMQ7nM/NquFojw3FaO9FOW5Kcp3U1KQha8gC1+Bm7wc50GFabj2d0+3ro4W2pY/Rjbg+da1ePKK0h1JiMOSgj8IDMMgEo3hD0bpDkbwJ16B7gjWHc3UNXbg747Q1R2hKxCmMxCmKxCmqztMRyDc85COI8ly2cnPcVLpy8HrcVGQG38V5rkozHNT6HHhyXEel90ezWbdQ7/A1xmh8ZSpnDLnzHTHEaJPKSn4SqnzgPuJP9N2idb6vkPWu4DHgBOBJuBKrfWuVBx7IAzDIBozCEdihKMxIpEYoUiMUDhKuNd0z3s4SjAcIxiOHniFDrx3h6J0hyKJ9yiBYIRozDh6kF5cDhu5WfaeyymebAe5WQ7ysp3k5cTn87Kd5OfE550OGVrXDN57Zjm+zXtpLslm/rXfS3ccIY4o6YKvlLIBvwPOBaqBNUqpF7TWm3o1uxFo0VpPUEpdBfxf4Mpkj304hmHwyKot1Lb4CQQjRKIGkUiMSDRGeP97NPaF3ifJsFosuJ023C4beTlOSr1ZZLnsuF12spw2st12slx2sl12Sn25RENRst12ctx2crIc5LgdOOzSy2W4adi7g+CKv2K1Wxh9679id0oXTGFuqTjDnw9s11rvBFBKrQQWAr0L/kLgp4npp4HfKqUsWusUlt24aCxG+TvPMrGzCQCLxYLFApZe02DBaomPwGixWA5a1/vd2sf8gfcD6wgBnUfPZ7fbiETivWIiQFviZQY1vbKZiTlzGbQ17sUdNuhYeBYjRk9JdyAhjioVBb8CqOo1Xw0s6KuN1jqilGoDioDGI+3Y683Gbu/fpQsjGmVGQRR/Z+IJSEbilWIGMJAS1PdHrOln1mxmzBWJRbDGotTOHsk3Fn0bqwlvMvP5zPuQFbNmM2suSE02U39o29LiH9B25Xf/yLQ9TsyaC8ybzWy5drdXcf9HvyPP6eG/z/8RTU1dR99oiJnte9abWbOZNRf0L9uRfjGk4rSkBhjZa74yseywbZRSdiCf+Ie3Qgwr3ZEgj278I4Zh8K0pV5Lrykl3JCGOWSrO8NcAE5VSY4kX9quAaw5p8wJwPfBP4DLg9cG4fi/EYPvLtr9SH2jknFFnoAonpDuOEP2S9Bm+1joC3A68DGwGntJab1RK/UwpdXGi2VKgSCm1HbgTuDvZ4wox1NY1bOD9fR8yMrecC8fJkMdi+EnJNXyt9Spg1SHLftxruhu4PBXHEiIdWrpbWbH5aRxWB4umXY3DauqPv4Q4LPN1LRDCZGJGjOWbVtIV8XPpxIsoyylNdyQhBkQKvhBH8fKuN9jWupNZvumcVn5oj2Mhhg8p+EIcwY7WXaza9QpeVwHXTL5MRsEUw5oUfCH64A8HeGTjCgzDYNG0q8lxZKc7khBJkYIvxGEYhsGTW56mJdjK+WPPYULB2HRHEiJpUvCFOIy3qt9nXcNnTCgYy3mjz053HCFSQgq+EIfY3V7FM9tfJNeRw+Jp12CzylDU4vggBV+IXvxhP0s3PEHMiLFo2tUUuPLTHUmIlJGCL0SCYRg8vvnPNHW3cN6Ys5lSOCndkYRIKSn4QiS8VvU26xs3MqlgPBeMPTfdcYRIOSn4QgBbmrfx3PZV5Dk9LJp2DVaL/NMQxx/5qRYZrynQzLKNT2K1WLn5hOvId5n3IRhCJEMKvshooWiIhz57jK6wnysmLWRc/ph0RxJi0EjBFxlr/81V1Z17ObV8AadVnJTuSEIMKin4ImO9svtN1tatY2zeaC6ftDDdcYQYdFLwRUb6qO5Tnt/5Nwpc+dx8wnUyvr3ICFLwRcbZ2baLxzb/CbfNxbdn3kC+Ky/dkYQYElLwRUZp8Dfx4PrlxIwYN06/lorcEemOJMSQServWKVUIfAnYAywC7hCa91ymHZR4LPE7B6t9cWHthFisHWGuvj9+qV0hru4Wl3C1CKV7khCDKlkz/DvBl7TWk8EXqPvh5MHtNazEi8p9mLIBSIBfvfpEur9jZwz6gzpkSMyUrIFfyGwPDG9HPh6kvsTIuVC0RAPfPoIezpqOGXEPL4+/oJ0RxIiLSyGYQx4Y6VUq9a6IDFtAVr2zx/SLgKsAyLAfVrr545l/5FI1LDbZWhaMXDhaJj/evcBPq3dzMkjT+R7J92A1SofXYnjWp/P4TzqNXyl1KtA2WFW3dt7RmttKKX6+u0xWmtdo5QaB7yulPpMa73jaMduafEfrUmffD4PDQ0dA95+sJg1F5g320BzRWNRlm58kk8bNjO9aDJXjb+UpqYuU2QbbGbNBebNZtZc0L9sPl/fQ4McteBrrc/pa51Sqk4pNUJrvU8pNQKo72MfNYn3nUqpN4HZwFELvhADFY6GWbLhCTY0bWZSwXhunH4ddulrLzJcsn/bvgBcn5i+Hnj+0AZKKa9SypWYLgZOBTYleVwh+tQdCfL79Y+woWkzUwoncdvMxThtjnTHEiLtki349wHnKqW2Aeck5lFKzVVKLUm0mQKsVUp9CrxB/Bq+FHwxKPzhAL9dt4StLduZWTyNW2cswmVzpjuWEKaQ1N+4Wusm4MuHWb4WuCkx/T5wQjLHEeJYtHS38sD6R6jp3Me80tlcN+UKeR6tEL3IRU1xXNjdXsWD6x+lLdTBlypO5opJC+UhJkIcQgq+GPY+rl/PY5tWEolFuXTiRZxVeRoWS58904TIWFLwxbAVM2L8bddrrPr8FVw2J7fNuI7pxVPSHUsI05KCL4altmA7j25aydaW7RS6vdw2Y5EMhCbEUUjBF8POxibNY5tW0hnuYkbxNK6dcjk5jux0xxLC9KTgi2GjOxLkxZ0v80b1u9gtNi6fuJAzKk+R6/VCHCMp+GJY2Ni0hZX6WZq7WyjJLmbxtGsY5alMdywhhhUp+MLU2oId/PGff+bdPWuwWqx8dfTZnD/myzjkzlkh+k0KvjClYDTEa3ve4pU9bxGKhhjtGck3p1wmH8wKkQQp+MJUorEoq/et5cXP/0F7qAOPI5dvzbqEmXmz5EYqIZIkBV+YQjAa4v29H/LanrdpCbbitDo4f8w5nDPqdEaO8Jl22FohhhMp+CKtWoNtvLf3Q96qfo+usB+H1cEZlafyldFnUuDKT3c8IY4rUvDFkIsZMTY1ad7b+yEbmjYTM2Jk27M4f8w5nFF5Ch5nbrojCnFckoIvhkTMiPF52x4+qV/PJw2f0RpsA2Ckp4JTy+czr3Q2brs7zSmFOL5JwReDJhgNsa1lB5uaNZ82bOwp8tn2LE4rX8Cp5QsYlSd96YUYKlLwRcqEomF2t1exs20XumU7O1o/J2JEgXiRP2nEXOaUzER5x8vjBoVIA/lXJwYkGotS66+nqqOGqo4adrdXsaejhmiiwAOMzC1nSpFiaqFiXP5oeRiJEGkmBV8ckT8coLG7icZAM7VdddR21VPrr6fO30AkFulpZ7VYGZlbwbiC0YzPH8v4gjHkOT1pTC6EOFRSBV8pdTnwU+LPrZ2feLTh4dqdB9wP2IAlWuv7kjmuSF40FqUz7Kcj1EF7qIOOUCeRxiDVTXW0BNto7W6lqbsFfyTwhW2dNiflOaVU5lYw0lPOSE8FFbkjcMqzY4UwtWTP8DcAlwAP9tVAKWUDfgecC1QDa5RSL8iDzPvHMAwiRpRwNEw4FiEcCxOOhQlFQ/FXLEwwGiIYCdIdDRKMBumOBAlEAgQi3fgjAfyRAF1hP11hP4HDFPLeHFY7Re5CxuWPpiiriOKsQkqzSyjLLsHrzpe7XoUYhpJ9iPlmAKXUkZrNB7ZrrXcm2q4EFgKDVvA/qf+MzoY2urqCABjG/jVG4r8GBxYZvZYemDcwMIxe7Y0DW+2f3r88hoFhxOLTiXUxI9bzHjPi62PEsDusdAfDRI0YMSNKNBYjakSJGlFiRmI6FiUSiy+LxCLxV69r4wNlt9jIcWTjdeVTmTuCXEcOHqeHPKeHPGcuo0pKsQZdFLjyybZnybDDQhxnhuIafgVQ1Wu+GlhwLBt6vdnY7f37oC8Si/LYWysJRcP92i5dbBYrNqsNm8UWf7facFjtZNldPdMOqx27zYHDasdpc+CwOXAmXi67C5fNicvuxGVzkuVw47a7yHK4ybK7yXZmkePIJtuRhdPmGLZF3Ocz7+cBZs1m1lxg3mxmzQWpyXbUgq+UehUoO8yqe7XWzyed4AhaWvwD2u7uud8j6g7S1hqARH2zcHChs2DhQO3bv9bSUxCtFstBy60WS6/tLAe9W3vmrT3zVos1sd7aM2+1WCgpzqO5OYAt0XZQC7ABBCEShHaC8Zkj8Pk8phyzxqy5wLzZzJoLzJvNrLmgf9mO9IvhqAVfa33Oscc6rBpgZK/5ysSyQVOaUxL/BtnM9z/P7XDjsA6Pvz6EEMeXobikswaYqJQaS7zQXwVcMwTHFUII0UtSXS2UUt9QSlUDJwMvKaVeTiwvV0qtAtBaR4DbgZeBzcBTWuuNycUWQgjRX8n20nkWePYwy/cCF/SaXwWsSuZYQgghkiOdqYUQIkNIwRdCiAwhBV8IITKEFHwhhMgQUvCFECJDSMEXQogMIQVfCCEyhBR8IYTIEFLwhRAiQ0jBF0KIDCEFXwghMoQUfCGEyBBS8IUQIkNIwRdCiAwhBV8IITKEFHwhhMgQUvCFECJDSMEXQogMkdQjDpVSlwM/BaYA87XWa/totwvoAKJARGs9N5njCiGE6L+kCj6wAbgEePAY2p6ltW5M8nhCCCEGKNmHmG8GUEqlJo0QQohBM1TX8A3gH0qpj5RStwzRMYUQQvRiMQzjiA2UUq8CZYdZda/W+vlEmzeBHxzhGn6F1rpGKVUCvAL8q9b67aOFi0Siht1uO1ozIYQQB1j6WnHUSzpa63OSPbrWuibxXq+UehaYDxy14Le0+Ad8TJ/PQ0NDx4C3HyxmzQXmzWbWXGDebGbNBebNZtZc0L9sPp+nz3WDfklHKZWjlPLsnwa+QvzDXiGEEEMoqYKvlPqGUqoaOBl4SSn1cmJ5uVJqVaJZKfCuUupT4EPgJa3135M5rhBCiP5LtpfOs8Czh1m+F7ggMb0TmJnMcYQQQiRP7rQVQogMIQVfCCEyhBR8IYTIEFLwhRAiQ0jBF0KIDCEFXwghMoQUfCGEyBBS8IUQIkNIwRdCiAwhBV8IITKEFHwhhMgQUvCFECJDSMEXQogMIQVfCCEyhBR8IYTIEFLwhRAiQ0jBF0KIDCEFXwghMoQUfCGEyBBJPdNWKfUL4CIgBOwAFmutWw/T7jzgfsAGLNFa35fMcYUQQvRfsmf4rwDTtdYzgK3ADw9toJSyAb8DzgemAlcrpaYmeVwhhBD9lNQZvtb6H71mVwOXHabZfGC71nongFJqJbAQ2JTMsYUQQvRPUgX/EDcAfzrM8gqgqtd8NbDgWHbo83ksyQTy+TzJbD5ozJoLzJvNrLnAvNnMmgvMm82suSA12Y5a8JVSrwJlh1l1r9b6+USbe4EI8GTSiYQQQgyKoxZ8rfU5R1qvlFoEXAh8WWttHKZJDTCy13xlYpkQQoghlGwvnfOAu4AztNb+PpqtASYqpcYSL/RXAdckc1whhBD9l2wvnd8CHuAVpdQ6pdQfAJRS5UqpVQBa6whwO/AysBl4Smu9McnjCiGE6CeLYRzuKowQQojjjdxpK4QQGUIKvhBCZIhU9sM3LaXUvwG/BHxa60YT5PkP4jefxYB6YJHWem96U8Ud63AZQ00pdTnwU2AKMF9rvTbNeUw5XIhSahnxXnP1Wuvp6c7Tm1JqJPAYUAoYwENa6/vTmwqUUm7gbcBFvCY+rbX+SXpTHZAYrWAtUKO1vjCZfR33Z/iJH7KvAHvSnaWXX2itZ2itZwEvAj9Od6BejjpcRppsAC4h/g8zrUw+XMijwHnpDtGHCPBvWuupwEnAd0zyfQsCZ2utZwKzgPOUUielOVNv3yPe4SVpx33BB35FvOuoaT6d1lq395rNwVzZ/pHoWQXx4TIq05lnP631Zq21TneOhJ7hQrTWIWD/cCFpp7V+G2hOd47D0Vrv01p/nJjuIF7EKtKbCrTWhta6MzHrSLxM8W9SKVUJfA1Ykor9HdeXdJRSC4n/GfSpUirdcQ6ilPo58C2gDTgrzXH60tdwGZluwMOFiDil1BhgNvBBmqMAPX+1fQRMAH6ntTZFLuDXxE9YUzLmw7Av+Eca+gG4h/jlnCF3tCEptNb3AvcqpX5I/D6FIbtmaNbhMo4llxj+lFK5wF+AOw75azdttNZRYJZSqgB4Vik1XWu9IZ2ZlFL7P4v5SCl1Zir2OewLfl9DPyilTgDGAvvP7iuBj5VS87XWtenKdRhPAqsYwoKfguEyBkU/vmfpJsOFDJBSykG82D+ptX4m3XkOpbVuVUq9QfxzkLQWfOBU4GKl1AWAG8hTSj2htb52oDsc9gW/L1rrz4CS/fNKqV3AXJP00pmotd6WmF0IbElnnt6OcbiMTCfDhQyAUsoCLAU2a63/O9159lNK+YBwothnAecC/zfNsdBa/5BEp4nEGf4Pkin2cBwXfJO7T8X/7IgBu4Hb0pynt98S7572SuIvo9Va67TnU0p9A/gN4ANeUkqt01p/NR1ZtNYRpdT+4UJswDKzDBeilPojcCZQrJSqBn6itV6a3lQ9TgWuAz5TSq1LLLtHa70qjZkARgDLE9fxrcSHf3kxzZkGhQytIIQQGSITumUKIYRACr4QQmQMKfhCCJEhpOALIUSGkIIvhBAZQgq+EEJkCCn4QgiRIf4/gI/bDgm7iccAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return max(0,z)\n",
    "\n",
    "X = [x/10 for x in range(-40, 40)]\n",
    "\n",
    "plt.plot(X, [sigmoid(x) for x in X])\n",
    "plt.plot(X, [tanh(x)    for x in X])\n",
    "plt.plot(X, [relu(x)    for x in X])\n",
    "plt.ylim(-2.0,2.0)\n",
    "plt.legend(['Sigmoid', 'Tanh', 'ReLU'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the outputs by forward propagation\n",
    "\n",
    "In a feedforward neural net we use $x$ as input to produce an output $ý$. The input provides inital information that propagates through the network to the output layer.\n",
    "\n",
    "Consider we have a network with two inputs of **x = [0.1, 0.9]**, a hidden layer with two units and one final output. Besides I add bias neurons (orange nodes) on each layer except input to get more flexibility to learn. To keep it simple and reproducible I intitalized all weights with fixed values.<br>\n",
    "Normally they will be intitialized randomly.\n",
    "\n",
    "As final output you get the value of **0.618**\n",
    "\n",
    "![Neural_net-forward.png](attachment:Neural_net-forward.png)\n",
    "\n",
    "To get the prediction of 0.618 you can execute this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Layer 1 --\n",
      "Inputs:\n",
      " [[0.17]\n",
      " [0.36]]\n",
      "Outputs:\n",
      " [[0.54239794]\n",
      " [0.58904043]]\n",
      "\n",
      "\n",
      "-- Layer 2 --\n",
      "Inputs:\n",
      " [[0.48519172]]\n",
      "Outputs:\n",
      " [[0.61897307]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [2,2,1]\n",
    "\n",
    "biases = [\n",
    "    [[0.1],[0.1]],              # on first hidden layer\n",
    "    [[0.2]]                     # on second layer (here output layer)\n",
    "]\n",
    "\n",
    "weights =[\n",
    "    [[-0.2, 0.1], [-0.1, 0.3]], # on first hidden layer\n",
    "    [[0.2, 0.3]]                # on second layer (here output layer)\n",
    "]\n",
    "\n",
    "def forward_propagation(a):\n",
    "    layer_inputs = []\n",
    "    activations  = []\n",
    "    for b, w in zip(biases, weights):\n",
    "        z = np.dot(w,a) + b\n",
    "        layer_inputs.append(z)\n",
    "        a = sigmoid(z)\n",
    "        activations.append(a)\n",
    "    return layer_inputs, activations\n",
    "\n",
    "X = np.array([ [0.1, 0.9] ]).T\n",
    "\n",
    "layer_inputs, activations = forward_propagation(X)\n",
    "\n",
    "for idx, i in enumerate(zip(layer_inputs, activations)):\n",
    "    print('-- Layer %i --' % (idx+1))\n",
    "    print('Inputs:\\n',  i[0])\n",
    "    print('Outputs:\\n', i[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening is we forward the input of **x = [0.1, 0.9]** to the output.\n",
    "\n",
    "First we calculate the inputs $net_j$ to the first hidden layer with it's outputs by using sigmoid as activation function $\\sigma(net_j)$. We use two definitions:\n",
    "\n",
    "$w_{i,j}$ is defined as the weight between the neuron $i$ and $j$<br>\n",
    "$x_i$ is defined as the input of neuron $i$\n",
    "\n",
    "\n",
    "The input $net_j$ to a neuron is the weighted sum of outputs $o_i$ of previous neurons. So we came up with the following equations:\n",
    "\n",
    "$net_j = w_{0,j} + \\sum\\limits_{i=1}^n x_i*w_{i,j}$<br>\n",
    "$o_j = \\frac{1}{(1+e^{-net_{j}})}$<br>\n",
    "<br>\n",
    "\n",
    "If we placed in the values for the hidden layer:\n",
    "\n",
    "$net_4 = 0.1 + (0.1 * -0.2) + (0.9 * 0.1)= 0.17$<br>\n",
    "$o_4 = \\frac{1}{(1+e^{-0.17})} = 0.542$<br>\n",
    "<br>\n",
    "\n",
    "$net_5 = 0.1 + (0.1 * -0.1) + (0.9 * 0.3)= 0.36$<br>\n",
    "$o_5 = \\frac{1}{(1+e^{-0.17})} = 0.589$<br>\n",
    "\n",
    "_________________\n",
    "The results from the hidden layer is the input to the next layer:\n",
    "\n",
    "$net_6 = 0.2 + (0.542 * 0.2) + (0.589 * 0.3) = 0.4851$<br>\n",
    "$o_6 = \\frac{1}{(1+e^{-0.4851})} = 0.6189$\n",
    "\n",
    "As you can see above, the final output is $ý=0.6189$\n",
    "\n",
    "Now we have to compare this result of $ý$ with the expected value of $y$ to measure the output error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation\n",
    "\n",
    "The goal of backpropagation is to compute the partial derivatives of the cost function. The objective is to get the ground truth by changing the weights of the network. In the previous example we used the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of final output: [[0.06627891]]\n",
      "\n",
      "New bias weight (3): [[0.21656973]]\n",
      "\n",
      "New weights (4 & 5):\n",
      " [[0.20898739 0.30976024]]\n",
      "\n",
      "Error of units (4 & 5):\n",
      " [[0.00329012]\n",
      " [0.00481328]]\n",
      "\n",
      "New bias weights (0):\n",
      " [[0.10082253]\n",
      " [0.10120332]]\n",
      "\n",
      "New weights (0):\n",
      " [[-0.19955386  0.1004845 ]\n",
      " [-0.09934732  0.3007088 ]]\n"
     ]
    }
   ],
   "source": [
    "y   = [0.9]\n",
    "eta = 0.25\n",
    "\n",
    "def back_propagation(y,verbose=0):\n",
    "    global biases, weights\n",
    "    new_b = [np.zeros(np.array(b).shape) for b in biases]\n",
    "    new_w = [np.zeros(np.array(w).shape) for w in weights]\n",
    "    \n",
    "    # Getting error of final output\n",
    "    error = (y - activations[-1]) * sigmoid(layer_inputs[-1]) * (1 - sigmoid(layer_inputs[-1]))\n",
    "    new_b[-1] = error\n",
    "    new_w[-1] = np.dot(error, activations[-2].transpose())\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('Error of final output:', error)\n",
    "        print('\\nNew bias weight (3):', error * eta + biases[-1])\n",
    "        print('\\nNew weights (4 & 5):\\n', activations[-2].T * error * eta + np.array(weights[-1]))\n",
    "\n",
    "    for layer in range(2, len(layers)):\n",
    "        z = layer_inputs[-layer]\n",
    "        sp = sigmoid(z) * (1 - sigmoid(z))\n",
    "        error = np.dot(np.array(weights[-layer+1]).T, error) * sp\n",
    "        new_b[-layer] = error\n",
    "        new_w[-layer] = np.dot(error, activations[-layer].T)\n",
    "        \n",
    "        if verbose == 1:\n",
    "            print('\\nError of units (4 & 5):\\n', error)\n",
    "            print('\\nNew bias weights (0):\\n', error * eta + np.array(biases[-layer]))\n",
    "            print('\\nNew weights (0):\\n', (np.array(new_w) * eta + weights)[0])\n",
    "    \n",
    "    # Updating the weights\n",
    "    biases  = np.array(new_b) * eta + biases\n",
    "    weights = np.array(new_w) * eta + weights\n",
    "    \n",
    "    return biases, weights\n",
    "    \n",
    "biases, weights = back_propagation(y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biases:\n",
      " [array([[0.10082253],\n",
      "       [0.10120332]]) array([[0.21656973]])]\n",
      "\n",
      "Weights:\n",
      " [array([[-0.19955386,  0.1004845 ],\n",
      "       [-0.09934732,  0.3007088 ]])\n",
      " array([[0.20898739, 0.30976024]])]\n"
     ]
    }
   ],
   "source": [
    "print('Biases:\\n',biases)\n",
    "\n",
    "print('\\nWeights:\\n',weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the code above you can use following equations of back propagation to verify the result. This step is the most important one and sometimes a bit confusing.\n",
    "\n",
    "We start with the last layer (output layer). $t_k$ is the correct target value of unit $k$. The actual predicted value by the neural net on unit $k$ is $o_k$. This lead us to the following equation to get the error on the **last layer**:<br>\n",
    "$\\delta_k = (t_k - o_k) * o_k * (1 - o_k)$\n",
    "\n",
    "This error is important for changing the weights between the last layer of unit $k$ and unit $j$ of the layer before:<br>\n",
    "$w_{j,k}^{new} = \\eta * \\delta_k * o_j + w_{j,k}^{old}$\n",
    "\n",
    "______________\n",
    "Calculating manually:\n",
    "\n",
    "$\\delta_6 = (0.9 - 0.619) * 0.619 * (1 - 0.619) = 0.0662$\n",
    "\n",
    "$w_{3,6}^{new} = 0.25 * 0.066 * 1.000 + 0.2 = 0.2165$\n",
    "\n",
    "$w_{4,6}^{new} = 0.25 * 0.066 * 0.542 + 0.2 = 0.2089$\n",
    "\n",
    "$w_{5,6}^{new} = 0.25 * 0.066 * 0.589 + 0.3 = 0.3097$\n",
    "\n",
    "______________\n",
    "\n",
    "On the layer before the output you have to use another but quite similiar equation for getting the error:<br>\n",
    "$\\delta_j = o_k * (1 - o_k) * \\sum\\limits_{j=0}^m \\delta_k * w_{j,k}$\n",
    "\n",
    "Using the error is the same like above:<br>\n",
    "$w_{i,j}^{new} = \\eta * \\delta_j * o_i + w_{i,j}^{old}$\n",
    "\n",
    "\n",
    "$\\delta_4 = 0.542 * (1 - 0.542) * (0.066 * 0.2) = 0.0033$\n",
    "\n",
    "$w_{0,4}^{new} = 0.25 * 0.0033 * 1.000 + 0.1 = 0.1008$\n",
    "\n",
    "$w_{1,4}^{new} = 0.25 * 0.0033 * 0.542 - 0.2 = -0.1995$\n",
    "\n",
    "$w_{2,4}^{new} = 0.25 * 0.0033 * 0.589 + 0.1 = 0.1004$\n",
    "\n",
    "______________\n",
    "\n",
    "$δ_5 = 0.589 * (1 - 0.589) * (0.066 * 0.3) = 0.0048$\n",
    "\n",
    "$w_{0,5}^{new} = 0.25 * 0.0048 * 1.000 + 0.1 = 0.1012$\n",
    "\n",
    "$w_{1,5}^{new} = 0.25 * 0.0048 * 0.542 - 0.1 = -0.0993$\n",
    "\n",
    "$w_{2,5}^{new} = 0.25 * 0.0048 * 0.589 + 0.3 = 0.3007$\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this step of back propagation we changed the weights of the neural net:\n",
    "\n",
    "![Neural_net-back.png](attachment:Neural_net-back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run `forward_propagation()` and `back_propagation()` in loop, the network will change the weights according to $y$.<br>\n",
    "I add some other values to make it more useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: [0.90551059 0.97500181 0.11433171]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([ [0.1, 0.9], [1.0,1.0], [0.1,0.1] ]).T\n",
    "y = np.array([0.9, 1.0, 0.1])\n",
    "\n",
    "for i in range(500):\n",
    "    _, activations = forward_propagation(X)\n",
    "    back_propagation(y)\n",
    "    \n",
    "for j in (activations[-1]):\n",
    "    print('Final output:',j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see after 500 iterations the final output seems to be very close to the target value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
